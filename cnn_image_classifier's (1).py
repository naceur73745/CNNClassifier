# -*- coding: utf-8 -*-
"""CNN image classifier's.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rec7cyZFSBhE6-DyI1XPWjD8XTl5MLU8

# Let's start with some basic concepts by playing around with code to gain a better understanding.
"""

import torch
from torch.utils.data import DataLoader
from torch import optim
import torchvision
from torchvision import transforms

import random
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from itertools import product
from copy import copy

# Check and set the device to GPU if available, else use CPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)

# Define a transformation for the dataset
transform = transforms.Compose([transforms.ToTensor()])

# Load the SVHN dataset for training
dataset = torchvision.datasets.SVHN(root='/data/torchvision', split='train', download=True, transform=transform)
print(dataset)

# Define the test dataset
test = torchvision.datasets.SVHN(root='/data/torchvision', split='test', download=True, transform=transform)
# Split the dataset into training and validation sets
train_size = int(len(dataset) * 0.8)
validation_size = len(dataset) - train_size
train, validation = torch.utils.data.random_split(dataset, [train_size, validation_size])
print(len(train))
print(len(test))

# Create a data loader for the training set
train_data_loader = DataLoader(train, batch_size=64)
images, targets = next(iter(train_data_loader))

# Function to convert tensor to array for easier plotting
def convert_tensor_to_array(tensor):
    image = np.asarray(tensor)
    # Move the first axis to the end
    image = np.rollaxis(image, 0, 3)
    return image

# Function to plot a batch of images
def plot_batch(images, targets):
    rows, cols = 8, 8
    fig, axs = plt.subplots(rows, cols, figsize=(10, 12))

    for i, (fig_row, fig_col) in enumerate(product(range(rows), range(cols))):
        print(f" the current i  :{i}  , fig_row : {fig_row} , fig_col : {fig_col}")
        tensor = images[i]

        img = convert_tensor_to_array(tensor)

        ax = axs[fig_row, fig_col]
        ax.imshow(img)

        ax.set_title(int(targets[i]))

        ax.axis('off')

plot_batch(images, targets)

"""
# Here, we will start the project where we will train an image recognition model using PyTorch and a neural network architecture, specifically on the CIFAR-10 dataset.
"""

# Device configuration
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Hyper-parameters
num_epochs = 5
batch_size = 4
learning_rate = 0.001

# Define transformations for the CIFAR-10 dataset
transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

# Load the CIFAR-10 dataset for training and testing
train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)

# Create data loaders for training and testing sets
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# Define classes for CIFAR-10
classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

# Function to display images
def imshow(img):
    print(f" the current image is  :{img}")
    img = img / 2 + 0.5  # Unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()

# Get some random training images
dataiter = iter(train_loader)
images, labels = next(dataiter)

# Show images
imshow(torchvision.utils.make_grid(images))

# Define a Convolutional Neural Network (CNN) model
class ConvNet(nn.Module):
    def __init__(self):
        super(ConvNet, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        # -> n, 3, 32, 32
        x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 14, 14
        x = self.pool(F.relu(self.conv2(x)))  # -> n, 16, 5, 5
        x = x.view(-1, 16 * 5 * 5)            # -> n, 400
        x = F.relu(self.fc1(x))               # -> n, 120
        x = F.relu(self.fc2(x))               # -> n, 84
        x = self.fc3(x)                       # -> n, 10
        return x

# Instantiate the model and move it to the device
model = ConvNet().to(device)

# Define loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)

n_total_steps = len(train_loader)
for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):
        # Origin shape: [4, 3, 32, 32] = 4, 3, 1024
        # Input layer: 3 input channels, 6 output channels, 5 kernel size
        images = images.to(device)
        labels = labels.to(device)

        # Forward pass
        outputs = model(images)
        loss = criterion(outputs, labels)

        # Backward and optimize
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        if (i+1) % 2000 == 0:
            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')

print('Finished Training')

'''
#PATH = './cnn.pth'
torch.save(model.state_dict(), PATH)
'''

# Here we don't need backpropagation and gradients
with torch.no_grad():
    n_correct = 0
    n_samples = 0
    n_class_correct = [0 for i in range(10)]
    n_class_samples = [0 for i in range(10)]
    for images, labels in test_loader:
        images = images.to(device)
        labels = labels.to(device)
        outputs = model(images)
        # Max returns (value, index)
        _, predicted = torch.max(outputs, 1)
        n_samples += labels.size(0)
        n_correct += (predicted == labels).sum().item()

        for i in range(batch_size):
            label = labels[i]
            pred = predicted[i]
            if (label == pred):
                n_class_correct[label] += 1
            n_class_samples[label] += 1

    acc = 100.0 * n_correct / n_samples
    print(f'Accuracy of the network: {acc} %')

    for i in range(10):
        acc = 100.0 * n_class_correct[i] / n_class_samples[i]
        print(f'Accuracy of {classes[i]}: {acc} %')
